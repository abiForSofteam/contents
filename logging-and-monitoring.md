Voici la premiÃ¨re partie de votre cours dÃ©taillÃ© sur le **Logging et le Monitoring dans Kubernetes**, axÃ©e sur la notion de **Labels et Selectors**, conformÃ©ment aux exigences du niveau CKA.

---

# ğŸ¯ Introduction : L'importance du Logging et du Monitoring dans Kubernetes

Dans un environnement Kubernetes, le **logging** et le **monitoring** sont essentiels pour :

* **Diagnostiquer les problÃ¨mes** : comprendre les dÃ©faillances des applications ou de l'infrastructure.
* **Assurer la performance** : surveiller l'utilisation des ressources et optimiser les performances.
* **Garantir la sÃ©curitÃ©** : dÃ©tecter les comportements anormaux ou les intrusions.
* **Maintenir la conformitÃ©** : rÃ©pondre aux exigences rÃ©glementaires en matiÃ¨re de traÃ§abilitÃ©.

Les **labels** et **selectors** jouent un rÃ´le crucial dans ces processus en permettant une organisation efficace des ressources et une sÃ©lection prÃ©cise des objets Ã  surveiller ou Ã  analyser.

---

# ğŸ·ï¸ Labels et Selectors

## ğŸ“Œ DÃ©finition

* **Labels** : Paires clÃ©/valeur attachÃ©es aux objets Kubernetes (pods, services, etc.) pour les identifier de maniÃ¨re significative.
* **Selectors** : MÃ©canismes permettant de sÃ©lectionner un ensemble d'objets en fonction de leurs labels.([CKA Journey][1])

Ces outils sont fondamentaux pour organiser, sÃ©lectionner et gÃ©rer les ressources au sein d'un cluster Kubernetes.&#x20;

---

## ğŸ§© ScÃ©narios et RÃ©solutions

### ğŸ”¹ ScÃ©nario 1 : Organisation des logs par environnement

**ProblÃ©matique** : Vous souhaitez sÃ©parer les logs des environnements de dÃ©veloppement, de test et de production.

**Solution** :

1. **Ajouter un label d'environnement aux pods** :

   ```bash
   kubectl label pods <nom-du-pod> environment=production
   ```



2. **Utiliser un selector pour filtrer les logs** :

   ```bash
   kubectl logs -l environment=production
   ```



### ğŸ”¹ ScÃ©nario 2 : Surveillance spÃ©cifique d'une application

**ProblÃ©matique** : Vous devez surveiller uniquement les pods d'une application spÃ©cifique.

**Solution** :

1. **Assigner un label d'application** :

   ```bash
   kubectl label pods <nom-du-pod> app=frontend
   ```



2. **Utiliser un selector pour surveiller ces pods** :

   ```bash
   kubectl get pods -l app=frontend
   ```



### ğŸ”¹ ScÃ©nario 3 : DÃ©ploiement ciblÃ© avec labels

**ProblÃ©matique** : Vous souhaitez dÃ©ployer un service uniquement sur des pods avec un certain label.([Kubernetes][2])

**Solution** :

1. **DÃ©finir le label sur les pods** :

   ```bash
   kubectl label pods <nom-du-pod> tier=backend
   ```



2. **Configurer le service avec un selector correspondant** :

   ```yaml
   selector:
     tier: backend
   ```



### ğŸ”¹ ScÃ©nario 4 : Nettoyage des ressources obsolÃ¨tes

**ProblÃ©matique** : Vous devez identifier et supprimer les ressources obsolÃ¨tes.

**Solution** :

1. **Lister les ressources avec un label spÃ©cifique** :

   ```bash
   kubectl get pods -l status=obsolete
   ```



2. **Supprimer ces ressources** :

   ```bash
   kubectl delete pods -l status=obsolete
   ```



### ğŸ”¹ ScÃ©nario 5 : Monitoring ciblÃ© avec Prometheus

**ProblÃ©matique** : Configurer Prometheus pour surveiller uniquement certains pods.

**Solution** :

1. **Assigner un label de monitoring aux pods** :

   ```bash
   kubectl label pods <nom-du-pod> monitoring=enabled
   ```



2. **Configurer Prometheus pour cibler ces pods via le label**.

---

Ces scÃ©narios illustrent l'utilisation des labels et selectors pour une gestion efficace du logging et du monitoring dans Kubernetes.

---

# ğŸ§ª **Taints and Tolerations**

## ğŸ¯ Objectif pÃ©dagogique

Les **taints** et **tolerations** permettent de **contrÃ´ler la planification (scheduling)** des pods sur les nÅ“uds dâ€™un cluster Kubernetes. Dans le cadre du **logging** et du **monitoring**, cette capacitÃ© est cruciale pour :

* Diriger les workloads sensibles (comme ceux de la tÃ©lÃ©mÃ©trie, Prometheus, Fluentd) vers des nÅ“uds dÃ©diÃ©s.
* Isoler les charges systÃ¨me pour limiter la pollution des logs.
* Prioriser les nÅ“uds en fonction de leur criticitÃ© ou performance.
* EmpÃªcher certains pods dâ€™Ãªtre programmÃ©s sur des nÅ“uds spÃ©cifiques.

---

## ğŸ“˜ Rappels de syntaxe

* **Taint** (appliquÃ© au nÅ“ud) :

  ```bash
  kubectl taint nodes <node-name> key=value:taint-effect
  ```

  *Effets possibles :* `NoSchedule`, `PreferNoSchedule`, `NoExecute`

* **Toleration** (dÃ©fini dans la spec du pod) :

  ```yaml
  tolerations:
    - key: "key"
      operator: "Equal"
      value: "value"
      effect: "NoSchedule"
  ```

---

## ğŸ“š 5 scÃ©narios concrets + rÃ©solutions

### ğŸ”¹ ScÃ©nario 1 : DÃ©diÃ© aux pods de monitoring

**ProblÃ©matique** : Vous souhaitez rÃ©server certains nÅ“uds aux seuls outils de monitoring (Prometheus, Grafanaâ€¦).

**Solution** :

1. Tainter les nÅ“uds dÃ©diÃ©s :

   ```bash
   kubectl taint nodes node-monitor monitoring=only:NoSchedule
   ```

2. TolÃ©rer ce taint dans les pods Prometheus :

   ```yaml
   tolerations:
     - key: "monitoring"
       operator: "Equal"
       value: "only"
       effect: "NoSchedule"
   ```

---

### ğŸ”¹ ScÃ©nario 2 : EmpÃªcher les pods applicatifs de se dÃ©ployer sur des nÅ“uds critiques

**ProblÃ©matique** : Vous avez des nÅ“uds critiques pour le systÃ¨me (logs, metrics) et vous ne voulez **aucun pod applicatif** dessus.

**Solution** :

1. Appliquer un taint bloquant :

   ```bash
   kubectl taint nodes node-logger reserved=true:NoSchedule
   ```

2. Aucun pod applicatif ne tolÃ©rera ce taint â‡’ ils seront exclus automatiquement.

---

### ğŸ”¹ ScÃ©nario 3 : RÃ©silience des logs aprÃ¨s une panne (NoExecute)

**ProblÃ©matique** : Un nÅ“ud hÃ©bergeant Fluent Bit redÃ©marre. Vous voulez que ses pods soient reschedulÃ©s ailleurs **uniquement s'ils tolÃ¨rent la condition.**

**Solution** :

1. Taint dynamique par Kubelet :
   (Exemple : `node.kubernetes.io/unreachable:NoExecute` appliquÃ© automatiquement.)

2. Pods de logs doivent avoir :

   ```yaml
   tolerations:
     - key: "node.kubernetes.io/unreachable"
       operator: "Exists"
       effect: "NoExecute"
       tolerationSeconds: 60
   ```

---

### ğŸ”¹ ScÃ©nario 4 : PrÃ©fÃ©rence douce avec `PreferNoSchedule`

**ProblÃ©matique** : Vous voulez **Ã©viter** que des pods normaux sâ€™exÃ©cutent sur un nÅ“ud oÃ¹ vous collectez les logs, mais sans interdire strictement.

**Solution** :

```bash
kubectl taint nodes node-log logcollect=true:PreferNoSchedule
```

â†’ Les pods Ã©viteront ce nÅ“ud sauf si aucun autre nâ€™est disponible.

---

### ğŸ”¹ ScÃ©nario 5 : Identification des nÅ“uds problÃ©matiques par les taints

**ProblÃ©matique** : Un nÅ“ud est dÃ©gradÃ© (latence Ã©levÃ©e des mÃ©triques). Vous voulez forcer les pods Ã  le quitter.

**Solution** :

1. Appliquer un taint temporaire :

   ```bash
   kubectl taint nodes node5 unstable=true:NoExecute
   ```

2. Seuls les pods avec :

   ```yaml
   tolerations:
     - key: "unstable"
       operator: "Equal"
       value: "true"
       effect: "NoExecute"
   ```

   resteront. Les autres seront expulsÃ©s.

---

## âœ… RÃ©sumÃ© des bonnes pratiques

* **SÃ©parer** les nÅ“uds de logs/metrics via des taints dÃ©diÃ©s.
* **Ã‰viter** les interfÃ©rences entre services dâ€™observabilitÃ© et applications.
* **TolÃ©rer intelligemment** les interruptions sur les pods critiques (logs/monitoring).
* **Utiliser `NoExecute`** pour garantir lâ€™Ã©vacuation rapide en cas de dÃ©faillance.

---



# ğŸ§© **Node Selectors**

---

## ğŸ¯ Objectif pÃ©dagogique

Les **Node Selectors** sont le moyen le plus simple de contrÃ´ler sur quel nÅ“ud un pod peut Ãªtre programmÃ©. Contrairement aux taints/tolerations (qui excluent ou incluent par contrainte), les Node Selectors **imposent** une correspondance directe entre un **label de nÅ“ud** et un **sÃ©lecteur du pod**.

Dans le contexte du **logging** et du **monitoring**, cette fonctionnalitÃ© est essentielle pourâ€¯:

* Forcer les pods de tÃ©lÃ©mÃ©trie Ã  rÃ©sider uniquement sur des nÅ“uds dÃ©diÃ©s.
* Garantir que les outils sensibles ne cohabitent pas avec des workloads utilisateurs.
* Organiser le cluster par **rÃ´le fonctionnel**.
* Simplifier le dÃ©ploiement de collecteurs de logs ou dâ€™agents metrics.

---

## ğŸ“˜ Syntaxe de base

1. Label sur le nÅ“ud :

   ```bash
   kubectl label nodes <node-name> role=monitoring
   ```

2. Dans la spec du pod :

   ```yaml
   nodeSelector:
     role: monitoring
   ```

---

## ğŸ“š 5 scÃ©narios concrets + rÃ©solutions

### ğŸ”¹ ScÃ©nario 1 : RÃ©server un nÅ“ud aux pods de Prometheus

**ProblÃ©matique** : Vous voulez que **Prometheus** s'exÃ©cute uniquement sur un nÅ“ud haute capacitÃ© `node-metrics`.

**Solution** :

1. Ajouter un label au nÅ“ud :

   ```bash
   kubectl label nodes node-metrics monitoring=true
   ```

2. DÃ©finir le `nodeSelector` dans le `deployment.yaml` :

   ```yaml
   nodeSelector:
     monitoring: "true"
   ```

---

### ğŸ”¹ ScÃ©nario 2 : Isoler les logs des utilisateurs

**ProblÃ©matique** : Fluent Bit collecte les logs des utilisateurs, mais ne doit pas Ãªtre sur leurs nÅ“uds.

**Solution** :

1. Label uniquement les nÅ“uds systÃ¨me :

   ```bash
   kubectl label nodes node-sys role=logging
   ```

2. Dans le `DaemonSet` Fluent Bit :

   ```yaml
   nodeSelector:
     role: logging
   ```

---

### ğŸ”¹ ScÃ©nario 3 : DÃ©dier un pod Grafana Ã  un nÅ“ud GPU sans exÃ©cution GPU

**ProblÃ©matique** : Un nÅ“ud dispose de beaucoup de ressources mais est inutilisÃ© ; vous souhaitez y mettre Grafana.

**Solution** :

1. Label du nÅ“ud :

   ```bash
   kubectl label nodes gpu-node metrics-heavy=true
   ```

2. SpÃ©cification dans Grafana :

   ```yaml
   nodeSelector:
     metrics-heavy: "true"
   ```

> âš ï¸ Le pod nâ€™accÃ¨de pas au GPU tant que `resources.limits` ne le demande pas.

---

### ğŸ”¹ ScÃ©nario 4 : Pod de log uniquement sur nÅ“ud localisÃ© (par datacenter)

**ProblÃ©matique** : Vous souhaitez que les pods de log restent **dans un datacenter spÃ©cifique** (ex : `dc=europe`).

**Solution** :

1. Label tous les nÅ“uds europÃ©ens :

   ```bash
   kubectl label nodes node-eu1 dc=europe
   ```

2. `nodeSelector` :

   ```yaml
   nodeSelector:
     dc: europe
   ```

---

### ğŸ”¹ ScÃ©nario 5 : DÃ©faillance si aucun nÅ“ud ne correspond

**ProblÃ©matique** : Que se passe-t-il si aucun nÅ“ud nâ€™a le label ?

**Explication** : Le pod **ne sera jamais programmÃ©**. Kubernetes ne gÃ©nÃ¨re pas d'erreur immÃ©diate, mais le pod restera en **`Pending`**.

**RÃ©solution** :

1. VÃ©rifier les nÅ“uds :

   ```bash
   kubectl get nodes --show-labels
   ```

2. Ajouter le bon label ou changer le `nodeSelector`.

---

## âœ… RÃ©sumÃ© des bonnes pratiques

* PrivilÃ©gier **Node Selectors** pour des affectations strictes simples.
* Toujours **documenter** les labels appliquÃ©s aux nÅ“uds (`role`, `zone`, `env`...).
* Coupler avec les **taints/tolerations** pour plus de contrÃ´le.
* Utiliser les Node Selectors pour vos **workloads de monitoring/logging dÃ©diÃ©s** afin de garantir leur stabilitÃ©.

---



---

# ğŸ§² **Node Affinity** â€” CKA Niveau AvancÃ©

---

## ğŸ¯ Objectif pÃ©dagogique

**Node Affinity** est une extension avancÃ©e de `nodeSelector`. Elle permet une **expression plus riche et plus flexible** des contraintes de placement des pods sur les nÅ“uds. LÃ  oÃ¹ `nodeSelector` exige une correspondance stricte, **Node Affinity permet de spÃ©cifier des prÃ©fÃ©rences et des contraintes plus granulaires**.

Dans le contexte du **logging** et du **monitoring**, cela est fondamental pourâ€¯:

* Prioriser certains nÅ“uds sans bloquer les autres.
* Imposer des rÃ¨gles **soft ou hard** pour le placement des agents de logs/metrics.
* Ã‰viter les conflits de ressources sans sacrifier la disponibilitÃ©.
* Permettre la haute rÃ©silience du systÃ¨me de monitoring.
* Adapter le placement selon des contextes gÃ©ographiques, de capacitÃ©, ou de criticitÃ©.

---

## ğŸ“˜ Types dâ€™affinitÃ©

| Type                                              | Sens                                                                                           |
| ------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| `requiredDuringSchedulingIgnoredDuringExecution`  | Hard affinity. Le pod **doit** Ãªtre programmÃ© sur un nÅ“ud correspondant.                       |
| `preferredDuringSchedulingIgnoredDuringExecution` | Soft affinity. Le pod **devrait prÃ©fÃ©rentiellement** Ãªtre programmÃ© sur un nÅ“ud correspondant. |

---

## ğŸ“š 5 scÃ©narios concrets + rÃ©solutions

### ğŸ”¹ ScÃ©nario 1 : Prioriser les nÅ“uds haute capacitÃ© pour Prometheus

**ProblÃ©matique** : Prometheus devrait prÃ©fÃ©rablement tourner sur des nÅ“uds marquÃ©s `capacity=high`.

**Solution** :

1. Label des nÅ“uds :

   ```bash
   kubectl label nodes node-a capacity=high
   ```

2. Dans le `Deployment` Prometheus :

   ```yaml
   affinity:
     nodeAffinity:
       preferredDuringSchedulingIgnoredDuringExecution:
         - weight: 100
           preference:
             matchExpressions:
               - key: capacity
                 operator: In
                 values:
                   - high
   ```

> âœ… RÃ©sultat : Prometheus sera **prÃ©fÃ©rentiellement** planifiÃ© sur ces nÅ“uds, mais pas bloquÃ© si indisponibles.

---

### ğŸ”¹ ScÃ©nario 2 : Forcer Loki Ã  tourner sur des nÅ“uds spÃ©cifiques

**ProblÃ©matique** : Loki doit obligatoirement tourner sur des nÅ“uds labellisÃ©s `role=logging`.

**Solution** :

1. Label :

   ```bash
   kubectl label nodes node-log1 role=logging
   ```

2. DÃ©finition dans la spec :

   ```yaml
   affinity:
     nodeAffinity:
       requiredDuringSchedulingIgnoredDuringExecution:
         nodeSelectorTerms:
           - matchExpressions:
               - key: role
                 operator: In
                 values:
                   - logging
   ```

> â— Si aucun nÅ“ud ne correspond, le pod restera en `Pending`.

---

### ğŸ”¹ ScÃ©nario 3 : DÃ©ployer un collecteur de logs **dans le mÃªme datacenter**

**ProblÃ©matique** : Vous voulez que les pods de logs restent dans le **mÃªme datacenter que d'autres pods** marquÃ©s `dc=europe`.

**Solution** :

1. Label :

   ```bash
   kubectl label nodes node-eu1 dc=europe
   ```

2. AffinitÃ© :

   ```yaml
   affinity:
     nodeAffinity:
       requiredDuringSchedulingIgnoredDuringExecution:
         nodeSelectorTerms:
           - matchExpressions:
               - key: dc
                 operator: In
                 values:
                   - europe
   ```

---

### ğŸ”¹ ScÃ©nario 4 : Minimiser les logs sur les nÅ“uds de calcul

**ProblÃ©matique** : Vous prÃ©fÃ©rez ne pas utiliser les nÅ“uds de calcul (`node-type=compute`) pour hÃ©berger Fluentd.

**Solution** : Exclure via un anti-affinity inversÃ©e.

```yaml
affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
            - key: node-type
              operator: NotIn
              values:
                - compute
```

> ğŸ§  Astuce : Cela **nâ€™interdit pas** totalement, mais Ã©vite par prÃ©fÃ©rence.

---

### ğŸ”¹ ScÃ©nario 5 : Multi-zones avec fallback

**ProblÃ©matique** : Vous voulez que vos outils de monitoring tournent en prioritÃ© sur `zone=eu-west-1`, mais puissent basculer ailleurs.

**Solution** :

```yaml
affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
            - key: zone
              operator: In
              values:
                - eu-west-1
```

> ğŸ”„ En cas de saturation ou de maintenance dans la zone cible, le pod est redirigÃ© automatiquement.

---

## âœ… RÃ©sumÃ© des bonnes pratiques

* Utilisez `preferredDuringScheduling...` pour la **rÃ©silience** et la **tolÃ©rance**.
* RÃ©servez `requiredDuringScheduling...` aux cas critiques.
* Combinez `nodeSelector`, `taints`, et `affinity` pour une orchestration fine.
* Pensez **â€œrÃ©silience dâ€™infrastructure monitoringâ€** : vos pods doivent pouvoir se relocaliser si nÃ©cessaire.



---

# ğŸ§© **DaemonSets** â€“ CKA Niveau AvancÃ©

---

## ğŸ¯ Objectif pÃ©dagogique

Un **DaemonSet** permet de s'assurer que **chaque nÅ“ud (ou un sous-ensemble ciblÃ©)** exÃ©cute une instance unique d'un pod. C'est un mÃ©canisme central dans la mise en Å“uvre dâ€™agents de **monitoring** (comme Node Exporter, cAdvisor) ou de **logging** (comme Fluentd, Fluent Bit, Logstash).

**RÃ´les clÃ©s dans le logging/monitoring** :

* DÃ©ploiement uniforme dâ€™agents de collecte de logs/metrics.
* Garantie de couverture complÃ¨te de lâ€™infrastructure.
* Adaptation automatique aux ajouts/retraits de nÅ“uds.
* RÃ©duction du bruit opÃ©rationnel (ex.â€¯: Ã©viter les pods orphelins ou manquants).

---

## ğŸ§ª ScÃ©narios & RÃ©solutions (5 cas pratiques)

---

### ğŸ”¹ ScÃ©nario 1 : DÃ©ployer Fluent Bit sur tous les nÅ“uds du cluster

**ProblÃ©matique** : Assurer une **collecte uniforme des logs systÃ¨me** sur tous les nÅ“uds.

**Solution** : CrÃ©ation dâ€™un DaemonSet classique.

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
spec:
  selector:
    matchLabels:
      name: fluent-bit
  template:
    metadata:
      labels:
        name: fluent-bit
    spec:
      containers:
        - name: fluent-bit
          image: fluent/fluent-bit:latest
          volumeMounts:
            - name: varlog
              mountPath: /var/log
      volumes:
        - name: varlog
          hostPath:
            path: /var/log
```

```bash
kubectl apply -f fluentbit-daemonset.yaml
```

> âœ… Une instance par nÅ“ud, logs centralisÃ©s vers un backend (ex : Elasticsearch).

---

### ğŸ”¹ ScÃ©nario 2 : DÃ©ployer Node Exporter uniquement sur les nÅ“uds Linux

**ProblÃ©matique** : Certains nÅ“uds exÃ©cutent Windows. Il faut **limiter le dÃ©ploiement aux nÅ“uds Linux**.

**Solution** : Utiliser `nodeSelector` dans le DaemonSet.

```yaml
spec:
  template:
    spec:
      nodeSelector:
        kubernetes.io/os: linux
```

> âœ… EmpÃªche les erreurs sur les nÅ“uds incompatibles.

---

### ğŸ”¹ ScÃ©nario 3 : EmpÃªcher le DaemonSet de tourner sur les nÅ“uds masters

**ProblÃ©matique** : On ne veut pas surcharger les nÅ“uds masters avec des pods de logging.

**Solution** : Taint les nÅ“uds masters et utilisez `tolerations`.

1. Tainter les nÅ“uds masters (si ce nâ€™est pas dÃ©jÃ  fait) :

   ```bash
   kubectl taint nodes node-master-1 node-role.kubernetes.io/master=:NoSchedule
   ```

2. Ne pas ajouter de toleration dans le DaemonSet â†’ pods non planifiÃ©s sur ces nÅ“uds.

> âœ… Isolation des workloads de monitoring des composants critiques.

---

### ğŸ”¹ ScÃ©nario 4 : Mettre Ã  jour Fluent Bit sans interruption

**ProblÃ©matique** : Vous devez **mettre Ã  jour lâ€™image de Fluent Bit** sans perdre la collecte des logs.

**Solution** : Mise Ã  jour par rolling update.

```yaml
updateStrategy:
  type: RollingUpdate
```

Puis modifier lâ€™image :

```yaml
containers:
  - name: fluent-bit
    image: fluent/fluent-bit:2.2.0
```

> âœ… Kubernetes remplace les pods un par un.

---

### ğŸ”¹ ScÃ©nario 5 : Diagnostiquer une absence de pod Fluent Bit sur un nÅ“ud

**ProblÃ©matique** : Un nÅ“ud ne possÃ¨de pas le pod `fluent-bit`, alors quâ€™il devrait.

**Solution** :

1. VÃ©rifier lâ€™Ã©tat du DaemonSet :

   ```bash
   kubectl get daemonset fluent-bit -n logging
   ```

2. VÃ©rifier si le nÅ“ud est schedulable :

   ```bash
   kubectl describe node <nom-node>
   ```

3. VÃ©rifier les taints :

   ```bash
   kubectl get nodes -o json | jq '.items[].spec.taints'
   ```

4. VÃ©rifier les events :

   ```bash
   kubectl describe pod fluent-bit-<hash> -n logging
   ```

> ğŸ¯ Identifier sâ€™il sâ€™agit dâ€™un problÃ¨me de `taint`, dâ€™espace disque, ou de restriction de `nodeSelector`.

---

## âœ… Bonnes pratiques

* Ne jamais utiliser DaemonSet sans `tolerations` lorsque des `taints` sont en place.
* Toujours **monitorer lâ€™Ã©tat global** des pods DaemonSet (pour dÃ©tecter des manques).
* PrÃ©fÃ©rer `hostPath` pour la lecture des fichiers de logs locaux.
* ImplÃ©menter une **update strategy** pour les upgrades contrÃ´lÃ©s.
* Utiliser un **namespace dÃ©diÃ©** (`monitoring`, `logging`) pour lâ€™isolation logique.

---



---

# ğŸ§© **Static Pods** â€“ CKA Niveau AvancÃ©

---

## ğŸ¯ IntÃ©rÃªt du sujet

Les **Static Pods** sont des pods qui ne sont pas gÃ©rÃ©s par le plan de contrÃ´le Kubernetes (câ€™est-Ã -dire, ils ne sont pas crÃ©Ã©s via lâ€™API server) mais directement gÃ©rÃ©s par le **kubelet** sur un nÅ“ud spÃ©cifique. Ils sont souvent utilisÃ©s pour :

* HÃ©berger des composants critiques (ex : etcd, kube-apiserver sur les nÅ“uds masters).
* DÃ©ployer des agents de monitoring/logging **avant** que le cluster ne soit complÃ¨tement fonctionnel.
* Diagnostiquer un nÅ“ud localement sans dÃ©pendance Ã  lâ€™API server.

### ğŸ§  Pourquoi câ€™est important pour le logging/monitoring ?

* Les static pods peuvent Ãªtre utilisÃ©s pour assurer une **surveillance de bas niveau**, mÃªme quand lâ€™API Server est inopÃ©rant.
* Ils permettent dâ€™installer un agent de monitoring/logging **de secours** sur un nÅ“ud problÃ©matique.
* Les logs des static pods sont **en local**, dans `/var/log/pods` et peuvent fournir un historique utile en cas de panne grave.

---

## ğŸ§ª ScÃ©narios & RÃ©solutions (5 cas pratiques)

---

### ğŸ”¹ ScÃ©nario 1 : DÃ©ployer un agent Node Exporter comme static pod sur un nÅ“ud

**ProblÃ¨me** : Le cluster nâ€™est pas encore initialisÃ©, mais vous souhaitez surveiller les performances dâ€™un nÅ“ud.

**Solution** : CrÃ©er un fichier dans `/etc/kubernetes/manifests/`.

```yaml
# /etc/kubernetes/manifests/node-exporter.yaml
apiVersion: v1
kind: Pod
metadata:
  name: node-exporter
  labels:
    app: monitoring
spec:
  containers:
    - name: node-exporter
      image: prom/node-exporter
      ports:
        - containerPort: 9100
      volumeMounts:
        - mountPath: /proc
          name: proc
          readOnly: true
  volumes:
    - name: proc
      hostPath:
        path: /proc
```

âœ… Le kubelet dÃ©tecte automatiquement le fichier YAML et crÃ©e le pod.

---

### ğŸ”¹ ScÃ©nario 2 : Obtenir les logs dâ€™un static pod en cas de problÃ¨me de kube-apiserver

**ProblÃ¨me** : Le kube-apiserver est inactif. Vous devez comprendre pourquoi.

**Solution** :

1. Lire les logs directement sur le nÅ“ud :

   ```bash
   journalctl -u kubelet
   ```

2. AccÃ©der aux logs du pod static :

   ```bash
   cat /var/log/pods/kube-system_kube-apiserver-<node>_*/kube-apiserver/*.log
   ```

âœ… Les logs Ã©tant gÃ©rÃ©s par le kubelet, ils sont disponibles mÃªme sans API Server.

---

### ğŸ”¹ ScÃ©nario 3 : Surveiller lâ€™Ã©tat dâ€™un static pod sur un nÅ“ud particulier

**ProblÃ¨me** : Un static pod dâ€™export mÃ©trique ne fonctionne pas correctement.

**Solution** :

```bash
# Voir les pods sur le nÅ“ud local
crictl pods

# Voir les logs du conteneur
crictl ps -a
crictl logs <container-id>
```

ğŸ’¡ `crictl` est souvent installÃ© avec `containerd` ou `cri-o`.

---

### ğŸ”¹ ScÃ©nario 4 : Un fichier manifest erronÃ© empÃªche le dÃ©marrage du static pod

**ProblÃ¨me** : Vous modifiez un fichier dans `/etc/kubernetes/manifests/`, mais le pod ne dÃ©marre pas.

**Solution** :

1. VÃ©rifier les logs du kubelet :

   ```bash
   journalctl -xeu kubelet
   ```

2. VÃ©rifier les erreurs de parsing YAML :

   * Kubelet **nâ€™interprÃ©tera pas** le fichier sâ€™il est invalide.
   * Corriger les erreurs dâ€™indentation ou de syntaxe.

âœ… Le kubelet est strict avec les fichiers statiques.

---

### ğŸ”¹ ScÃ©nario 5 : Vous voulez superviser la disponibilitÃ© des composants static pods du plan de contrÃ´le

**ProblÃ¨me** : Vous devez collecter des mÃ©triques sur les pods `etcd`, `kube-scheduler`, etc. â€“ tous dÃ©ployÃ©s en static pods.

**Solution** :

1. Configurer Prometheus pour dÃ©couvrir les endpoints via les fichiers `kubelet` exposÃ©s en `/metrics`.
2. AccÃ©der aux metrics via le port 10255 (non sÃ©curisÃ©, Ã  restreindre !) ou configurer le port 10250 (authentifiÃ©).
3. Exemple de `prometheus.yml` :

```yaml
- job_name: 'kubelets'
  scheme: https
  static_configs:
    - targets:
      - 192.168.1.100:10250
  tls_config:
    insecure_skip_verify: true
```

âœ… Permet une visibilitÃ© fine sur les composants critiques.

---

## âœ… Bonnes pratiques

* Toujours valider les fichiers YAML via `yamllint` avant dÃ©pÃ´t dans `/etc/kubernetes/manifests/`.
* Utiliser `crictl` ou `journalctl` pour dÃ©boguer localement.
* Ne pas dÃ©ployer Ã  la lÃ©gÃ¨re en static pod : impossible Ã  gÃ©rer par `kubectl`.
* PrÃ©fÃ©rer un DaemonSet si le cluster est stable et initialisÃ©.
* Utiliser un processus CI/CD mÃªme pour les fichiers de static pods.

---



---

# ğŸ§© **Multiple Schedulers** â€“ Niveau CKA

---

## ğŸ¯ IntÃ©rÃªt du sujet

Kubernetes utilise un **scheduler** (planificateur) par dÃ©faut qui dÃ©cide **sur quel nÅ“ud** dÃ©ployer un pod, en fonction de diffÃ©rentes contraintes (ressources, affinitÃ©s, etc.).
Cependant, dans certains cas avancÃ©s, il est utile, voire nÃ©cessaire, de **dÃ©ployer un scheduler personnalisÃ©**. Câ€™est lÃ  que les **multiple schedulers** entrent en jeu.

### ğŸ” Pourquoi câ€™est utile ?

* Pour des **workloads critiques** nÃ©cessitant une stratÃ©gie de planification personnalisÃ©e.
* Pour sÃ©parer le scheduling de **diffÃ©rents types d'applications** (par ex. batch vs temps rÃ©el).
* Pour des **tests ou expÃ©rimentations** sans impacter le scheduler par dÃ©faut.
* Pour observer et auditer les dÃ©cisions de planification de maniÃ¨re fine.

### ğŸ§  RÃ´le dans le logging & monitoring :

* Tracer quel scheduler a pris une dÃ©cision.
* Diagnostiquer des pods non planifiÃ©s.
* Superviser la santÃ© et lâ€™activitÃ© de plusieurs schedulers.

---

## ğŸ§ª ScÃ©narios & RÃ©solutions (5 cas pratiques)

---

### ğŸ”¹ ScÃ©nario 1 : DÃ©ployer un scheduler personnalisÃ© dans le cluster

**ProblÃ¨me** : Vous souhaitez quâ€™un scheduler planifie uniquement les pods avec une annotation spÃ©ciale.

**Solution** :

1. CrÃ©er un fichier de dÃ©ploiement personnalisÃ© du scheduler :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-scheduler
  namespace: kube-system
spec:
  containers:
    - name: scheduler
      image: k8s.gcr.io/kube-scheduler:v1.29.0
      command:
        - kube-scheduler
        - --scheduler-name=my-scheduler
        - --leader-elect=false
```

2. Le pod est gÃ©rÃ© par le kubelet comme static pod ou dÃ©ploiement rÃ©gulier.

âœ… Votre scheduler est maintenant actif et prÃªt Ã  gÃ©rer des pods.

---

### ğŸ”¹ ScÃ©nario 2 : Forcer un pod Ã  Ãªtre planifiÃ© par un scheduler personnalisÃ©

**ProblÃ¨me** : Vous avez deux schedulers, et vous voulez quâ€™un pod spÃ©cifique soit pris en charge par le second.

**Solution** :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  schedulerName: my-scheduler
  containers:
    - name: busybox
      image: busybox
      command: ["sleep", "3600"]
```

âœ… Le champ `schedulerName` indique clairement quel scheduler doit planifier ce pod.

---

### ğŸ”¹ ScÃ©nario 3 : Diagnostiquer un pod non planifiÃ©

**ProblÃ¨me** : Un pod nâ€™est pas assignÃ© Ã  un nÅ“ud. Aucun Ã©vÃ©nement nâ€™est gÃ©nÃ©rÃ©.

**Solution** :

1. VÃ©rifier le champ `schedulerName` :

   ```bash
   kubectl get pod test-pod -o=jsonpath='{.spec.schedulerName}'
   ```

2. VÃ©rifier si le scheduler indiquÃ© est actif :

   ```bash
   kubectl get pods -n kube-system | grep my-scheduler
   ```

3. Afficher les logs du scheduler :

   ```bash
   kubectl logs my-scheduler -n kube-system
   ```

âœ… Cela permet de savoir si le scheduler est tombÃ©, indisponible ou inopÃ©rant.

---

### ğŸ”¹ ScÃ©nario 4 : Ajouter de la journalisation personnalisÃ©e Ã  un scheduler

**ProblÃ¨me** : Vous voulez suivre toutes les dÃ©cisions de planification.

**Solution** :

* Utiliser les options de log du scheduler :

```bash
--v=4
```

* Ou bien rediriger la sortie dans un fichier si vous gÃ©rez en static pod :

```yaml
command:
  - kube-scheduler
  - --scheduler-name=my-scheduler
  - --v=5
```

âœ… Vous obtenez plus de dÃ©tails sur le processus de planification.

---

### ğŸ”¹ ScÃ©nario 5 : Monitorer lâ€™activitÃ© des schedulers multiples avec Prometheus

**ProblÃ¨me** : Vous devez superviser les performances et la latence des planificateurs.

**Solution** :

1. Exposer les mÃ©triques via lâ€™option `--bind-address=0.0.0.0 --secure-port=10259`.

2. Ajouter dans Prometheus :

```yaml
- job_name: 'custom-schedulers'
  metrics_path: /metrics
  static_configs:
    - targets: ['my-scheduler.kube-system.svc.cluster.local:10259']
```

âœ… Vous pouvez comparer les performances entre plusieurs planificateurs.

---

## âœ… Bonnes pratiques

* Utiliser un `schedulerName` explicite et cohÃ©rent dans vos pods.
* Activer une politique de logs adaptÃ©e Ã  vos besoins (`--v=4` ou supÃ©rieur).
* Isoler le rÃ´le de chaque scheduler via des labels ou annotations.
* Surveiller la charge et les dÃ©cisions avec Prometheus ou les logs JSON du scheduler.
* Ne pas rendre un scheduler critique si celui-ci nâ€™est pas HA ou supervisÃ©.

---



---

# ğŸ§© **Configuring Scheduler Profiles** â€“ Niveau CKA

---

## ğŸ¯ IntÃ©rÃªt du sujet

Kubernetes permet une configuration fine du **scheduler** Ã  lâ€™aide de **profiles de scheduling**.
Les **Scheduler Profiles** permettent de dÃ©finir **plusieurs logiques de planification** Ã  lâ€™intÃ©rieur dâ€™un mÃªme scheduler. Chaque profile peut avoir ses propres plugins activÃ©s/dÃ©sactivÃ©s et ses propres rÃ¨gles de priorisation.

### ğŸ” Pourquoi est-ce important ?

* Pour **adapter dynamiquement le comportement du scheduler** selon des cas dâ€™usage (batch, temps rÃ©el, criticitÃ©, etc.).
* Pour **ajouter ou dÃ©sactiver des plugins** de scoring, de prÃ©emption ou de filtrage.
* Pour **gÃ©rer des workloads hÃ©tÃ©rogÃ¨nes** sans crÃ©er plusieurs schedulers.
* Pour **centraliser la planification** tout en diversifiant la stratÃ©gie.

### ğŸ§  RÃ´le dans le Logging & Monitoring :

* Auditer quel profile a Ã©tÃ© utilisÃ©.
* Analyser les logs pour comprendre pourquoi un pod a Ã©tÃ© ou non planifiÃ©.
* Surveiller le comportement dâ€™un profile dans Prometheus.

---

## ğŸ§ª ScÃ©narios & RÃ©solutions (5 cas pratiques)

---

### ğŸ”¹ ScÃ©nario 1 : Activer plusieurs profiles dans un seul scheduler

**ProblÃ¨me** : Vous voulez quâ€™un mÃªme scheduler utilise plusieurs stratÃ©gies de planification selon le `schedulerName`.

**Solution** : Configurer le scheduler avec un fichier YAML.

1. CrÃ©ez un fichier de configuration `/etc/kubernetes/scheduler-config.yaml` :

```yaml
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
profiles:
  - schedulerName: default-scheduler
    plugins:
      score:
        enabled:
          - name: NodeResourcesBalancedAllocation
  - schedulerName: realtime-scheduler
    plugins:
      score:
        enabled:
          - name: NodeResourcesLeastAllocated
```

2. Lancer le scheduler avec :

```bash
kube-scheduler --config=/etc/kubernetes/scheduler-config.yaml
```

âœ… Vous avez maintenant deux comportements diffÃ©rents selon le schedulerName utilisÃ© dans les pods.

---

### ğŸ”¹ ScÃ©nario 2 : Forcer un pod Ã  utiliser un profile particulier

**ProblÃ¨me** : Vous souhaitez quâ€™un pod utilise le profile "realtime-scheduler".

**Solution** :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: realtime-app
spec:
  schedulerName: realtime-scheduler
  containers:
    - name: app
      image: busybox
      command: ["sleep", "3600"]
```

âœ… Le pod sera traitÃ© selon la logique du profile correspondant dans le scheduler configurÃ©.

---

### ğŸ”¹ ScÃ©nario 3 : Diagnostiquer un mauvais comportement de planification

**ProblÃ¨me** : Des pods sont mal rÃ©partis sur les nÅ“uds malgrÃ© la configuration.

**Solution** :

1. Activer les logs verbeux du scheduler :

   ```bash
   kube-scheduler --v=5 --config=/etc/kubernetes/scheduler-config.yaml
   ```

2. VÃ©rifier quel plugin est utilisÃ© pour le scoring :

   ```bash
   grep "Score plugin" /var/log/kube-scheduler.log
   ```

âœ… Permet de confirmer que le bon profile a Ã©tÃ© appliquÃ©.

---

### ğŸ”¹ ScÃ©nario 4 : Ajouter un plugin personnalisÃ© dans un profile

**ProblÃ¨me** : Vous avez un plugin personnalisÃ© Ã  insÃ©rer dans le processus de planification.

**Solution** :

1. Compiler le plugin avec Go, lâ€™enregistrer dans le scheduler.

2. Ajouter dans la configuration :

```yaml
profiles:
  - schedulerName: custom-scheduler
    plugins:
      score:
        enabled:
          - name: MyCustomScorer
    pluginConfig:
      - name: MyCustomScorer
        args:
          weight: 10
```

âœ… Le scheduler utilisera votre plugin avec le profile configurÃ©.

---

### ğŸ”¹ ScÃ©nario 5 : Monitorer les profils de scheduling avec des mÃ©triques

**ProblÃ¨me** : Vous souhaitez observer le comportement de chaque profile.

**Solution** :

1. Activer lâ€™endpoint de mÃ©triques (dÃ©jÃ  activÃ© par dÃ©faut sur `:10259`).

2. Interroger les mÃ©triques :

```bash
curl -k https://localhost:10259/metrics | grep scheduler_profile
```

3. Ajouter un job Prometheus :

```yaml
- job_name: 'scheduler-profiles'
  metrics_path: /metrics
  static_configs:
    - targets: ['localhost:10259']
```

âœ… Vous obtenez des mÃ©triques par profile comme `scheduler_plugin_execution_duration_seconds`.

---

## âœ… Bonnes pratiques

* Toujours documenter les profils et leur usage prÃ©vu.
* VÃ©rifier que les `schedulerName` utilisÃ©s dans les pods correspondent bien Ã  ceux des profiles.
* Ne pas dupliquer inutilement des profils ; factoriser les comportements communs.
* Utiliser les logs de haut niveau (`--v=5`) pour observer les dÃ©cisions prises.
* Superviser les performances de chaque profile avec Prometheus.

---

## ğŸ“˜ Conclusion gÃ©nÃ©rale du module Logging & Monitoring (niveau CKA)

Les notions couvertes dans ce cours â€” de *Labels and Selectors* Ã  *Scheduler Profiles* â€” permettent non seulement une meilleure maÃ®trise du **comportement du planificateur Kubernetes**, mais aussi une **visibilitÃ© opÃ©rationnelle** essentielle Ã  tout ingÃ©nieur DevOps ou SRE.

Vous avez dÃ©sormais :

* des **scÃ©narios rÃ©els**, directement applicables,
* les **commandes Kubernetes** prÃ©cises pour diagnostiquer et intervenir,
* une comprÃ©hension approfondie du rÃ´le de **lâ€™observabilitÃ©** dans la fiabilitÃ© dâ€™un cluster.

---








