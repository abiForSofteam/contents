Voici la premi√®re partie de votre cours d√©taill√© sur le **Logging et le Monitoring dans Kubernetes**, ax√©e sur la notion de **Labels et Selectors**, conform√©ment aux exigences du niveau CKA.

---

# üéØ Introduction : L'importance du Logging et du Monitoring dans Kubernetes

Dans un environnement Kubernetes, le **logging** et le **monitoring** sont essentiels pour :

* **Diagnostiquer les probl√®mes** : comprendre les d√©faillances des applications ou de l'infrastructure.
* **Assurer la performance** : surveiller l'utilisation des ressources et optimiser les performances.
* **Garantir la s√©curit√©** : d√©tecter les comportements anormaux ou les intrusions.
* **Maintenir la conformit√©** : r√©pondre aux exigences r√©glementaires en mati√®re de tra√ßabilit√©.

Les **labels** et **selectors** jouent un r√¥le crucial dans ces processus en permettant une organisation efficace des ressources et une s√©lection pr√©cise des objets √† surveiller ou √† analyser.

---

# üè∑Ô∏è Labels et Selectors

## üìå D√©finition

* **Labels** : Paires cl√©/valeur attach√©es aux objets Kubernetes (pods, services, etc.) pour les identifier de mani√®re significative.
* **Selectors** : M√©canismes permettant de s√©lectionner un ensemble d'objets en fonction de leurs labels.([CKA Journey][1])

Ces outils sont fondamentaux pour organiser, s√©lectionner et g√©rer les ressources au sein d'un cluster Kubernetes.&#x20;

---

## üß© Sc√©narios et R√©solutions

### üîπ Sc√©nario 1 : Organisation des logs par environnement

**Probl√©matique** : Vous souhaitez s√©parer les logs des environnements de d√©veloppement, de test et de production.

**Solution** :

1. **Ajouter un label d'environnement aux pods** :

   ```bash
   kubectl label pods <nom-du-pod> environment=production
   ```



2. **Utiliser un selector pour filtrer les logs** :

   ```bash
   kubectl logs -l environment=production
   ```



### üîπ Sc√©nario 2 : Surveillance sp√©cifique d'une application

**Probl√©matique** : Vous devez surveiller uniquement les pods d'une application sp√©cifique.

**Solution** :

1. **Assigner un label d'application** :

   ```bash
   kubectl label pods <nom-du-pod> app=frontend
   ```



2. **Utiliser un selector pour surveiller ces pods** :

   ```bash
   kubectl get pods -l app=frontend
   ```



### üîπ Sc√©nario 3 : D√©ploiement cibl√© avec labels

**Probl√©matique** : Vous souhaitez d√©ployer un service uniquement sur des pods avec un certain label.([Kubernetes][2])

**Solution** :

1. **D√©finir le label sur les pods** :

   ```bash
   kubectl label pods <nom-du-pod> tier=backend
   ```



2. **Configurer le service avec un selector correspondant** :

   ```yaml
   selector:
     tier: backend
   ```



### üîπ Sc√©nario 4 : Nettoyage des ressources obsol√®tes

**Probl√©matique** : Vous devez identifier et supprimer les ressources obsol√®tes.

**Solution** :

1. **Lister les ressources avec un label sp√©cifique** :

   ```bash
   kubectl get pods -l status=obsolete
   ```



2. **Supprimer ces ressources** :

   ```bash
   kubectl delete pods -l status=obsolete
   ```



### üîπ Sc√©nario 5 : Monitoring cibl√© avec Prometheus

**Probl√©matique** : Configurer Prometheus pour surveiller uniquement certains pods.

**Solution** :

1. **Assigner un label de monitoring aux pods** :

   ```bash
   kubectl label pods <nom-du-pod> monitoring=enabled
   ```



2. **Configurer Prometheus pour cibler ces pods via le label**.

---

Ces sc√©narios illustrent l'utilisation des labels et selectors pour une gestion efficace du logging et du monitoring dans Kubernetes.

---

# üß™ **Taints and Tolerations**

## üéØ Objectif p√©dagogique

Les **taints** et **tolerations** permettent de **contr√¥ler la planification (scheduling)** des pods sur les n≈ìuds d‚Äôun cluster Kubernetes. Dans le cadre du **logging** et du **monitoring**, cette capacit√© est cruciale pour :

* Diriger les workloads sensibles (comme ceux de la t√©l√©m√©trie, Prometheus, Fluentd) vers des n≈ìuds d√©di√©s.
* Isoler les charges syst√®me pour limiter la pollution des logs.
* Prioriser les n≈ìuds en fonction de leur criticit√© ou performance.
* Emp√™cher certains pods d‚Äô√™tre programm√©s sur des n≈ìuds sp√©cifiques.

---

## üìò Rappels de syntaxe

* **Taint** (appliqu√© au n≈ìud) :

  ```bash
  kubectl taint nodes <node-name> key=value:taint-effect
  ```

  *Effets possibles :* `NoSchedule`, `PreferNoSchedule`, `NoExecute`

* **Toleration** (d√©fini dans la spec du pod) :

  ```yaml
  tolerations:
    - key: "key"
      operator: "Equal"
      value: "value"
      effect: "NoSchedule"
  ```

---

## üìö 5 sc√©narios concrets + r√©solutions

### üîπ Sc√©nario 1 : D√©di√© aux pods de monitoring

**Probl√©matique** : Vous souhaitez r√©server certains n≈ìuds aux seuls outils de monitoring (Prometheus, Grafana‚Ä¶).

**Solution** :

1. Tainter les n≈ìuds d√©di√©s :

   ```bash
   kubectl taint nodes node-monitor monitoring=only:NoSchedule
   ```

2. Tol√©rer ce taint dans les pods Prometheus :

   ```yaml
   tolerations:
     - key: "monitoring"
       operator: "Equal"
       value: "only"
       effect: "NoSchedule"
   ```

---

### üîπ Sc√©nario 2 : Emp√™cher les pods applicatifs de se d√©ployer sur des n≈ìuds critiques

**Probl√©matique** : Vous avez des n≈ìuds critiques pour le syst√®me (logs, metrics) et vous ne voulez **aucun pod applicatif** dessus.

**Solution** :

1. Appliquer un taint bloquant :

   ```bash
   kubectl taint nodes node-logger reserved=true:NoSchedule
   ```

2. Aucun pod applicatif ne tol√©rera ce taint ‚áí ils seront exclus automatiquement.

---

### üîπ Sc√©nario 3 : R√©silience des logs apr√®s une panne (NoExecute)

**Probl√©matique** : Un n≈ìud h√©bergeant Fluent Bit red√©marre. Vous voulez que ses pods soient reschedul√©s ailleurs **uniquement s'ils tol√®rent la condition.**

**Solution** :

1. Taint dynamique par Kubelet :
   (Exemple : `node.kubernetes.io/unreachable:NoExecute` appliqu√© automatiquement.)

2. Pods de logs doivent avoir :

   ```yaml
   tolerations:
     - key: "node.kubernetes.io/unreachable"
       operator: "Exists"
       effect: "NoExecute"
       tolerationSeconds: 60
   ```

---

### üîπ Sc√©nario 4 : Pr√©f√©rence douce avec `PreferNoSchedule`

**Probl√©matique** : Vous voulez **√©viter** que des pods normaux s‚Äôex√©cutent sur un n≈ìud o√π vous collectez les logs, mais sans interdire strictement.

**Solution** :

```bash
kubectl taint nodes node-log logcollect=true:PreferNoSchedule
```

‚Üí Les pods √©viteront ce n≈ìud sauf si aucun autre n‚Äôest disponible.

---

### üîπ Sc√©nario 5 : Identification des n≈ìuds probl√©matiques par les taints

**Probl√©matique** : Un n≈ìud est d√©grad√© (latence √©lev√©e des m√©triques). Vous voulez forcer les pods √† le quitter.

**Solution** :

1. Appliquer un taint temporaire :

   ```bash
   kubectl taint nodes node5 unstable=true:NoExecute
   ```

2. Seuls les pods avec :

   ```yaml
   tolerations:
     - key: "unstable"
       operator: "Equal"
       value: "true"
       effect: "NoExecute"
   ```

   resteront. Les autres seront expuls√©s.

---

## ‚úÖ R√©sum√© des bonnes pratiques

* **S√©parer** les n≈ìuds de logs/metrics via des taints d√©di√©s.
* **√âviter** les interf√©rences entre services d‚Äôobservabilit√© et applications.
* **Tol√©rer intelligemment** les interruptions sur les pods critiques (logs/monitoring).
* **Utiliser `NoExecute`** pour garantir l‚Äô√©vacuation rapide en cas de d√©faillance.

---



# üß© **Node Selectors**

---

## üéØ Objectif p√©dagogique

Les **Node Selectors** sont le moyen le plus simple de contr√¥ler sur quel n≈ìud un pod peut √™tre programm√©. Contrairement aux taints/tolerations (qui excluent ou incluent par contrainte), les Node Selectors **imposent** une correspondance directe entre un **label de n≈ìud** et un **s√©lecteur du pod**.

Dans le contexte du **logging** et du **monitoring**, cette fonctionnalit√© est essentielle pour‚ÄØ:

* Forcer les pods de t√©l√©m√©trie √† r√©sider uniquement sur des n≈ìuds d√©di√©s.
* Garantir que les outils sensibles ne cohabitent pas avec des workloads utilisateurs.
* Organiser le cluster par **r√¥le fonctionnel**.
* Simplifier le d√©ploiement de collecteurs de logs ou d‚Äôagents metrics.

---

## üìò Syntaxe de base

1. Label sur le n≈ìud :

   ```bash
   kubectl label nodes <node-name> role=monitoring
   ```

2. Dans la spec du pod :

   ```yaml
   nodeSelector:
     role: monitoring
   ```

---

## üìö 5 sc√©narios concrets + r√©solutions

### üîπ Sc√©nario 1 : R√©server un n≈ìud aux pods de Prometheus

**Probl√©matique** : Vous voulez que **Prometheus** s'ex√©cute uniquement sur un n≈ìud haute capacit√© `node-metrics`.

**Solution** :

1. Ajouter un label au n≈ìud :

   ```bash
   kubectl label nodes node-metrics monitoring=true
   ```

2. D√©finir le `nodeSelector` dans le `deployment.yaml` :

   ```yaml
   nodeSelector:
     monitoring: "true"
   ```

---

### üîπ Sc√©nario 2 : Isoler les logs des utilisateurs

**Probl√©matique** : Fluent Bit collecte les logs des utilisateurs, mais ne doit pas √™tre sur leurs n≈ìuds.

**Solution** :

1. Label uniquement les n≈ìuds syst√®me :

   ```bash
   kubectl label nodes node-sys role=logging
   ```

2. Dans le `DaemonSet` Fluent Bit :

   ```yaml
   nodeSelector:
     role: logging
   ```

---

### üîπ Sc√©nario 3 : D√©dier un pod Grafana √† un n≈ìud GPU sans ex√©cution GPU

**Probl√©matique** : Un n≈ìud dispose de beaucoup de ressources mais est inutilis√© ; vous souhaitez y mettre Grafana.

**Solution** :

1. Label du n≈ìud :

   ```bash
   kubectl label nodes gpu-node metrics-heavy=true
   ```

2. Sp√©cification dans Grafana :

   ```yaml
   nodeSelector:
     metrics-heavy: "true"
   ```

> ‚ö†Ô∏è Le pod n‚Äôacc√®de pas au GPU tant que `resources.limits` ne le demande pas.

---

### üîπ Sc√©nario 4 : Pod de log uniquement sur n≈ìud localis√© (par datacenter)

**Probl√©matique** : Vous souhaitez que les pods de log restent **dans un datacenter sp√©cifique** (ex : `dc=europe`).

**Solution** :

1. Label tous les n≈ìuds europ√©ens :

   ```bash
   kubectl label nodes node-eu1 dc=europe
   ```

2. `nodeSelector` :

   ```yaml
   nodeSelector:
     dc: europe
   ```

---

### üîπ Sc√©nario 5 : D√©faillance si aucun n≈ìud ne correspond

**Probl√©matique** : Que se passe-t-il si aucun n≈ìud n‚Äôa le label ?

**Explication** : Le pod **ne sera jamais programm√©**. Kubernetes ne g√©n√®re pas d'erreur imm√©diate, mais le pod restera en **`Pending`**.

**R√©solution** :

1. V√©rifier les n≈ìuds :

   ```bash
   kubectl get nodes --show-labels
   ```

2. Ajouter le bon label ou changer le `nodeSelector`.

---

## ‚úÖ R√©sum√© des bonnes pratiques

* Privil√©gier **Node Selectors** pour des affectations strictes simples.
* Toujours **documenter** les labels appliqu√©s aux n≈ìuds (`role`, `zone`, `env`...).
* Coupler avec les **taints/tolerations** pour plus de contr√¥le.
* Utiliser les Node Selectors pour vos **workloads de monitoring/logging d√©di√©s** afin de garantir leur stabilit√©.

---



---

# üß≤ **Node Affinity** ‚Äî CKA Niveau Avanc√©

---

## üéØ Objectif p√©dagogique

**Node Affinity** est une extension avanc√©e de `nodeSelector`. Elle permet une **expression plus riche et plus flexible** des contraintes de placement des pods sur les n≈ìuds. L√† o√π `nodeSelector` exige une correspondance stricte, **Node Affinity permet de sp√©cifier des pr√©f√©rences et des contraintes plus granulaires**.

Dans le contexte du **logging** et du **monitoring**, cela est fondamental pour‚ÄØ:

* Prioriser certains n≈ìuds sans bloquer les autres.
* Imposer des r√®gles **soft ou hard** pour le placement des agents de logs/metrics.
* √âviter les conflits de ressources sans sacrifier la disponibilit√©.
* Permettre la haute r√©silience du syst√®me de monitoring.
* Adapter le placement selon des contextes g√©ographiques, de capacit√©, ou de criticit√©.

---

## üìò Types d‚Äôaffinit√©

| Type                                              | Sens                                                                                           |
| ------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| `requiredDuringSchedulingIgnoredDuringExecution`  | Hard affinity. Le pod **doit** √™tre programm√© sur un n≈ìud correspondant.                       |
| `preferredDuringSchedulingIgnoredDuringExecution` | Soft affinity. Le pod **devrait pr√©f√©rentiellement** √™tre programm√© sur un n≈ìud correspondant. |

---

## üìö 5 sc√©narios concrets + r√©solutions

### üîπ Sc√©nario 1 : Prioriser les n≈ìuds haute capacit√© pour Prometheus

**Probl√©matique** : Prometheus devrait pr√©f√©rablement tourner sur des n≈ìuds marqu√©s `capacity=high`.

**Solution** :

1. Label des n≈ìuds :

   ```bash
   kubectl label nodes node-a capacity=high
   ```

2. Dans le `Deployment` Prometheus :

   ```yaml
   affinity:
     nodeAffinity:
       preferredDuringSchedulingIgnoredDuringExecution:
         - weight: 100
           preference:
             matchExpressions:
               - key: capacity
                 operator: In
                 values:
                   - high
   ```

> ‚úÖ R√©sultat : Prometheus sera **pr√©f√©rentiellement** planifi√© sur ces n≈ìuds, mais pas bloqu√© si indisponibles.

---

### üîπ Sc√©nario 2 : Forcer Loki √† tourner sur des n≈ìuds sp√©cifiques

**Probl√©matique** : Loki doit obligatoirement tourner sur des n≈ìuds labellis√©s `role=logging`.

**Solution** :

1. Label :

   ```bash
   kubectl label nodes node-log1 role=logging
   ```

2. D√©finition dans la spec :

   ```yaml
   affinity:
     nodeAffinity:
       requiredDuringSchedulingIgnoredDuringExecution:
         nodeSelectorTerms:
           - matchExpressions:
               - key: role
                 operator: In
                 values:
                   - logging
   ```

> ‚ùó Si aucun n≈ìud ne correspond, le pod restera en `Pending`.

---

### üîπ Sc√©nario 3 : D√©ployer un collecteur de logs **dans le m√™me datacenter**

**Probl√©matique** : Vous voulez que les pods de logs restent dans le **m√™me datacenter que d'autres pods** marqu√©s `dc=europe`.

**Solution** :

1. Label :

   ```bash
   kubectl label nodes node-eu1 dc=europe
   ```

2. Affinit√© :

   ```yaml
   affinity:
     nodeAffinity:
       requiredDuringSchedulingIgnoredDuringExecution:
         nodeSelectorTerms:
           - matchExpressions:
               - key: dc
                 operator: In
                 values:
                   - europe
   ```

---

### üîπ Sc√©nario 4 : Minimiser les logs sur les n≈ìuds de calcul

**Probl√©matique** : Vous pr√©f√©rez ne pas utiliser les n≈ìuds de calcul (`node-type=compute`) pour h√©berger Fluentd.

**Solution** : Exclure via un anti-affinity invers√©e.

```yaml
affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
            - key: node-type
              operator: NotIn
              values:
                - compute
```

> üß† Astuce : Cela **n‚Äôinterdit pas** totalement, mais √©vite par pr√©f√©rence.

---

### üîπ Sc√©nario 5 : Multi-zones avec fallback

**Probl√©matique** : Vous voulez que vos outils de monitoring tournent en priorit√© sur `zone=eu-west-1`, mais puissent basculer ailleurs.

**Solution** :

```yaml
affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
            - key: zone
              operator: In
              values:
                - eu-west-1
```

> üîÑ En cas de saturation ou de maintenance dans la zone cible, le pod est redirig√© automatiquement.

---

## ‚úÖ R√©sum√© des bonnes pratiques

* Utilisez `preferredDuringScheduling...` pour la **r√©silience** et la **tol√©rance**.
* R√©servez `requiredDuringScheduling...` aux cas critiques.
* Combinez `nodeSelector`, `taints`, et `affinity` pour une orchestration fine.
* Pensez **‚Äúr√©silience d‚Äôinfrastructure monitoring‚Äù** : vos pods doivent pouvoir se relocaliser si n√©cessaire.



---

# üß© **DaemonSets** ‚Äì CKA Niveau Avanc√©

---

## üéØ Objectif p√©dagogique

Un **DaemonSet** permet de s'assurer que **chaque n≈ìud (ou un sous-ensemble cibl√©)** ex√©cute une instance unique d'un pod. C'est un m√©canisme central dans la mise en ≈ìuvre d‚Äôagents de **monitoring** (comme Node Exporter, cAdvisor) ou de **logging** (comme Fluentd, Fluent Bit, Logstash).

**R√¥les cl√©s dans le logging/monitoring** :

* D√©ploiement uniforme d‚Äôagents de collecte de logs/metrics.
* Garantie de couverture compl√®te de l‚Äôinfrastructure.
* Adaptation automatique aux ajouts/retraits de n≈ìuds.
* R√©duction du bruit op√©rationnel (ex.‚ÄØ: √©viter les pods orphelins ou manquants).

---

## üß™ Sc√©narios & R√©solutions (5 cas pratiques)

---

### üîπ Sc√©nario 1 : D√©ployer Fluent Bit sur tous les n≈ìuds du cluster

**Probl√©matique** : Assurer une **collecte uniforme des logs syst√®me** sur tous les n≈ìuds.

**Solution** : Cr√©ation d‚Äôun DaemonSet classique.

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
spec:
  selector:
    matchLabels:
      name: fluent-bit
  template:
    metadata:
      labels:
        name: fluent-bit
    spec:
      containers:
        - name: fluent-bit
          image: fluent/fluent-bit:latest
          volumeMounts:
            - name: varlog
              mountPath: /var/log
      volumes:
        - name: varlog
          hostPath:
            path: /var/log
```

```bash
kubectl apply -f fluentbit-daemonset.yaml
```

> ‚úÖ Une instance par n≈ìud, logs centralis√©s vers un backend (ex : Elasticsearch).

---

### üîπ Sc√©nario 2 : D√©ployer Node Exporter uniquement sur les n≈ìuds Linux

**Probl√©matique** : Certains n≈ìuds ex√©cutent Windows. Il faut **limiter le d√©ploiement aux n≈ìuds Linux**.

**Solution** : Utiliser `nodeSelector` dans le DaemonSet.

```yaml
spec:
  template:
    spec:
      nodeSelector:
        kubernetes.io/os: linux
```

> ‚úÖ Emp√™che les erreurs sur les n≈ìuds incompatibles.

---

### üîπ Sc√©nario 3 : Emp√™cher le DaemonSet de tourner sur les n≈ìuds masters

**Probl√©matique** : On ne veut pas surcharger les n≈ìuds masters avec des pods de logging.

**Solution** : Taint les n≈ìuds masters et utilisez `tolerations`.

1. Tainter les n≈ìuds masters (si ce n‚Äôest pas d√©j√† fait) :

   ```bash
   kubectl taint nodes node-master-1 node-role.kubernetes.io/master=:NoSchedule
   ```

2. Ne pas ajouter de toleration dans le DaemonSet ‚Üí pods non planifi√©s sur ces n≈ìuds.

> ‚úÖ Isolation des workloads de monitoring des composants critiques.

---

### üîπ Sc√©nario 4 : Mettre √† jour Fluent Bit sans interruption

**Probl√©matique** : Vous devez **mettre √† jour l‚Äôimage de Fluent Bit** sans perdre la collecte des logs.

**Solution** : Mise √† jour par rolling update.

```yaml
updateStrategy:
  type: RollingUpdate
```

Puis modifier l‚Äôimage :

```yaml
containers:
  - name: fluent-bit
    image: fluent/fluent-bit:2.2.0
```

> ‚úÖ Kubernetes remplace les pods un par un.

---

### üîπ Sc√©nario 5 : Diagnostiquer une absence de pod Fluent Bit sur un n≈ìud

**Probl√©matique** : Un n≈ìud ne poss√®de pas le pod `fluent-bit`, alors qu‚Äôil devrait.

**Solution** :

1. V√©rifier l‚Äô√©tat du DaemonSet :

   ```bash
   kubectl get daemonset fluent-bit -n logging
   ```

2. V√©rifier si le n≈ìud est schedulable :

   ```bash
   kubectl describe node <nom-node>
   ```

3. V√©rifier les taints :

   ```bash
   kubectl get nodes -o json | jq '.items[].spec.taints'
   ```

4. V√©rifier les events :

   ```bash
   kubectl describe pod fluent-bit-<hash> -n logging
   ```

> üéØ Identifier s‚Äôil s‚Äôagit d‚Äôun probl√®me de `taint`, d‚Äôespace disque, ou de restriction de `nodeSelector`.

---

## ‚úÖ Bonnes pratiques

* Ne jamais utiliser DaemonSet sans `tolerations` lorsque des `taints` sont en place.
* Toujours **monitorer l‚Äô√©tat global** des pods DaemonSet (pour d√©tecter des manques).
* Pr√©f√©rer `hostPath` pour la lecture des fichiers de logs locaux.
* Impl√©menter une **update strategy** pour les upgrades contr√¥l√©s.
* Utiliser un **namespace d√©di√©** (`monitoring`, `logging`) pour l‚Äôisolation logique.

---



---

# üß© **Static Pods** ‚Äì CKA Niveau Avanc√©

---

## üéØ Int√©r√™t du sujet

Les **Static Pods** sont des pods qui ne sont pas g√©r√©s par le plan de contr√¥le Kubernetes (c‚Äôest-√†-dire, ils ne sont pas cr√©√©s via l‚ÄôAPI server) mais directement g√©r√©s par le **kubelet** sur un n≈ìud sp√©cifique. Ils sont souvent utilis√©s pour :

* H√©berger des composants critiques (ex : etcd, kube-apiserver sur les n≈ìuds masters).
* D√©ployer des agents de monitoring/logging **avant** que le cluster ne soit compl√®tement fonctionnel.
* Diagnostiquer un n≈ìud localement sans d√©pendance √† l‚ÄôAPI server.

### üß† Pourquoi c‚Äôest important pour le logging/monitoring ?

* Les static pods peuvent √™tre utilis√©s pour assurer une **surveillance de bas niveau**, m√™me quand l‚ÄôAPI Server est inop√©rant.
* Ils permettent d‚Äôinstaller un agent de monitoring/logging **de secours** sur un n≈ìud probl√©matique.
* Les logs des static pods sont **en local**, dans `/var/log/pods` et peuvent fournir un historique utile en cas de panne grave.

---

## üß™ Sc√©narios & R√©solutions (5 cas pratiques)

---

### üîπ Sc√©nario 1 : D√©ployer un agent Node Exporter comme static pod sur un n≈ìud

**Probl√®me** : Le cluster n‚Äôest pas encore initialis√©, mais vous souhaitez surveiller les performances d‚Äôun n≈ìud.

**Solution** : Cr√©er un fichier dans `/etc/kubernetes/manifests/`.

```yaml
# /etc/kubernetes/manifests/node-exporter.yaml
apiVersion: v1
kind: Pod
metadata:
  name: node-exporter
  labels:
    app: monitoring
spec:
  containers:
    - name: node-exporter
      image: prom/node-exporter
      ports:
        - containerPort: 9100
      volumeMounts:
        - mountPath: /proc
          name: proc
          readOnly: true
  volumes:
    - name: proc
      hostPath:
        path: /proc
```

‚úÖ Le kubelet d√©tecte automatiquement le fichier YAML et cr√©e le pod.

---

### üîπ Sc√©nario 2 : Obtenir les logs d‚Äôun static pod en cas de probl√®me de kube-apiserver

**Probl√®me** : Le kube-apiserver est inactif. Vous devez comprendre pourquoi.

**Solution** :

1. Lire les logs directement sur le n≈ìud :

   ```bash
   journalctl -u kubelet
   ```

2. Acc√©der aux logs du pod static :

   ```bash
   cat /var/log/pods/kube-system_kube-apiserver-<node>_*/kube-apiserver/*.log
   ```

‚úÖ Les logs √©tant g√©r√©s par le kubelet, ils sont disponibles m√™me sans API Server.

---

### üîπ Sc√©nario 3 : Surveiller l‚Äô√©tat d‚Äôun static pod sur un n≈ìud particulier

**Probl√®me** : Un static pod d‚Äôexport m√©trique ne fonctionne pas correctement.

**Solution** :

```bash
# Voir les pods sur le n≈ìud local
crictl pods

# Voir les logs du conteneur
crictl ps -a
crictl logs <container-id>
```

üí° `crictl` est souvent install√© avec `containerd` ou `cri-o`.

---

### üîπ Sc√©nario 4 : Un fichier manifest erron√© emp√™che le d√©marrage du static pod

**Probl√®me** : Vous modifiez un fichier dans `/etc/kubernetes/manifests/`, mais le pod ne d√©marre pas.

**Solution** :

1. V√©rifier les logs du kubelet :

   ```bash
   journalctl -xeu kubelet
   ```

2. V√©rifier les erreurs de parsing YAML :

   * Kubelet **n‚Äôinterpr√©tera pas** le fichier s‚Äôil est invalide.
   * Corriger les erreurs d‚Äôindentation ou de syntaxe.

‚úÖ Le kubelet est strict avec les fichiers statiques.

---

### üîπ Sc√©nario 5 : Vous voulez superviser la disponibilit√© des composants static pods du plan de contr√¥le

**Probl√®me** : Vous devez collecter des m√©triques sur les pods `etcd`, `kube-scheduler`, etc. ‚Äì tous d√©ploy√©s en static pods.

**Solution** :

1. Configurer Prometheus pour d√©couvrir les endpoints via les fichiers `kubelet` expos√©s en `/metrics`.
2. Acc√©der aux metrics via le port 10255 (non s√©curis√©, √† restreindre !) ou configurer le port 10250 (authentifi√©).
3. Exemple de `prometheus.yml` :

```yaml
- job_name: 'kubelets'
  scheme: https
  static_configs:
    - targets:
      - 192.168.1.100:10250
  tls_config:
    insecure_skip_verify: true
```

‚úÖ Permet une visibilit√© fine sur les composants critiques.

---

## ‚úÖ Bonnes pratiques

* Toujours valider les fichiers YAML via `yamllint` avant d√©p√¥t dans `/etc/kubernetes/manifests/`.
* Utiliser `crictl` ou `journalctl` pour d√©boguer localement.
* Ne pas d√©ployer √† la l√©g√®re en static pod : impossible √† g√©rer par `kubectl`.
* Pr√©f√©rer un DaemonSet si le cluster est stable et initialis√©.
* Utiliser un processus CI/CD m√™me pour les fichiers de static pods.

---



---

# üß© **Multiple Schedulers** ‚Äì Niveau CKA

---

## üéØ Int√©r√™t du sujet

Kubernetes utilise un **scheduler** (planificateur) par d√©faut qui d√©cide **sur quel n≈ìud** d√©ployer un pod, en fonction de diff√©rentes contraintes (ressources, affinit√©s, etc.).
Cependant, dans certains cas avanc√©s, il est utile, voire n√©cessaire, de **d√©ployer un scheduler personnalis√©**. C‚Äôest l√† que les **multiple schedulers** entrent en jeu.

### üîé Pourquoi c‚Äôest utile ?

* Pour des **workloads critiques** n√©cessitant une strat√©gie de planification personnalis√©e.
* Pour s√©parer le scheduling de **diff√©rents types d'applications** (par ex. batch vs temps r√©el).
* Pour des **tests ou exp√©rimentations** sans impacter le scheduler par d√©faut.
* Pour observer et auditer les d√©cisions de planification de mani√®re fine.

### üß† R√¥le dans le logging & monitoring :

* Tracer quel scheduler a pris une d√©cision.
* Diagnostiquer des pods non planifi√©s.
* Superviser la sant√© et l‚Äôactivit√© de plusieurs schedulers.

---

## üß™ Sc√©narios & R√©solutions (5 cas pratiques)

---

### üîπ Sc√©nario 1 : D√©ployer un scheduler personnalis√© dans le cluster

**Probl√®me** : Vous souhaitez qu‚Äôun scheduler planifie uniquement les pods avec une annotation sp√©ciale.

**Solution** :

1. Cr√©er un fichier de d√©ploiement personnalis√© du scheduler :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-scheduler
  namespace: kube-system
spec:
  containers:
    - name: scheduler
      image: k8s.gcr.io/kube-scheduler:v1.29.0
      command:
        - kube-scheduler
        - --scheduler-name=my-scheduler
        - --leader-elect=false
```

2. Le pod est g√©r√© par le kubelet comme static pod ou d√©ploiement r√©gulier.

‚úÖ Votre scheduler est maintenant actif et pr√™t √† g√©rer des pods.

---

### üîπ Sc√©nario 2 : Forcer un pod √† √™tre planifi√© par un scheduler personnalis√©

**Probl√®me** : Vous avez deux schedulers, et vous voulez qu‚Äôun pod sp√©cifique soit pris en charge par le second.

**Solution** :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  schedulerName: my-scheduler
  containers:
    - name: busybox
      image: busybox
      command: ["sleep", "3600"]
```

‚úÖ Le champ `schedulerName` indique clairement quel scheduler doit planifier ce pod.

---

### üîπ Sc√©nario 3 : Diagnostiquer un pod non planifi√©

**Probl√®me** : Un pod n‚Äôest pas assign√© √† un n≈ìud. Aucun √©v√©nement n‚Äôest g√©n√©r√©.

**Solution** :

1. V√©rifier le champ `schedulerName` :

   ```bash
   kubectl get pod test-pod -o=jsonpath='{.spec.schedulerName}'
   ```

2. V√©rifier si le scheduler indiqu√© est actif :

   ```bash
   kubectl get pods -n kube-system | grep my-scheduler
   ```

3. Afficher les logs du scheduler :

   ```bash
   kubectl logs my-scheduler -n kube-system
   ```

‚úÖ Cela permet de savoir si le scheduler est tomb√©, indisponible ou inop√©rant.

---

### üîπ Sc√©nario 4 : Ajouter de la journalisation personnalis√©e √† un scheduler

**Probl√®me** : Vous voulez suivre toutes les d√©cisions de planification.

**Solution** :

* Utiliser les options de log du scheduler :

```bash
--v=4
```

* Ou bien rediriger la sortie dans un fichier si vous g√©rez en static pod :

```yaml
command:
  - kube-scheduler
  - --scheduler-name=my-scheduler
  - --v=5
```

‚úÖ Vous obtenez plus de d√©tails sur le processus de planification.

---

### üîπ Sc√©nario 5 : Monitorer l‚Äôactivit√© des schedulers multiples avec Prometheus

**Probl√®me** : Vous devez superviser les performances et la latence des planificateurs.

**Solution** :

1. Exposer les m√©triques via l‚Äôoption `--bind-address=0.0.0.0 --secure-port=10259`.

2. Ajouter dans Prometheus :

```yaml
- job_name: 'custom-schedulers'
  metrics_path: /metrics
  static_configs:
    - targets: ['my-scheduler.kube-system.svc.cluster.local:10259']
```

‚úÖ Vous pouvez comparer les performances entre plusieurs planificateurs.

---

## ‚úÖ Bonnes pratiques

* Utiliser un `schedulerName` explicite et coh√©rent dans vos pods.
* Activer une politique de logs adapt√©e √† vos besoins (`--v=4` ou sup√©rieur).
* Isoler le r√¥le de chaque scheduler via des labels ou annotations.
* Surveiller la charge et les d√©cisions avec Prometheus ou les logs JSON du scheduler.
* Ne pas rendre un scheduler critique si celui-ci n‚Äôest pas HA ou supervis√©.

---



---

# üß© **Configuring Scheduler Profiles** ‚Äì Niveau CKA

---

## üéØ Int√©r√™t du sujet

Kubernetes permet une configuration fine du **scheduler** √† l‚Äôaide de **profiles de scheduling**.
Les **Scheduler Profiles** permettent de d√©finir **plusieurs logiques de planification** √† l‚Äôint√©rieur d‚Äôun m√™me scheduler. Chaque profile peut avoir ses propres plugins activ√©s/d√©sactiv√©s et ses propres r√®gles de priorisation.

### üîé Pourquoi est-ce important ?

* Pour **adapter dynamiquement le comportement du scheduler** selon des cas d‚Äôusage (batch, temps r√©el, criticit√©, etc.).
* Pour **ajouter ou d√©sactiver des plugins** de scoring, de pr√©emption ou de filtrage.
* Pour **g√©rer des workloads h√©t√©rog√®nes** sans cr√©er plusieurs schedulers.
* Pour **centraliser la planification** tout en diversifiant la strat√©gie.

### üß† R√¥le dans le Logging & Monitoring :

* Auditer quel profile a √©t√© utilis√©.
* Analyser les logs pour comprendre pourquoi un pod a √©t√© ou non planifi√©.
* Surveiller le comportement d‚Äôun profile dans Prometheus.

---

## üß™ Sc√©narios & R√©solutions (5 cas pratiques)

---

### üîπ Sc√©nario 1 : Activer plusieurs profiles dans un seul scheduler

**Probl√®me** : Vous voulez qu‚Äôun m√™me scheduler utilise plusieurs strat√©gies de planification selon le `schedulerName`.

**Solution** : Configurer le scheduler avec un fichier YAML.

1. Cr√©ez un fichier de configuration `/etc/kubernetes/scheduler-config.yaml` :

```yaml
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
profiles:
  - schedulerName: default-scheduler
    plugins:
      score:
        enabled:
          - name: NodeResourcesBalancedAllocation
  - schedulerName: realtime-scheduler
    plugins:
      score:
        enabled:
          - name: NodeResourcesLeastAllocated
```

2. Lancer le scheduler avec :

```bash
kube-scheduler --config=/etc/kubernetes/scheduler-config.yaml
```

‚úÖ Vous avez maintenant deux comportements diff√©rents selon le schedulerName utilis√© dans les pods.

---

### üîπ Sc√©nario 2 : Forcer un pod √† utiliser un profile particulier

**Probl√®me** : Vous souhaitez qu‚Äôun pod utilise le profile "realtime-scheduler".

**Solution** :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: realtime-app
spec:
  schedulerName: realtime-scheduler
  containers:
    - name: app
      image: busybox
      command: ["sleep", "3600"]
```

‚úÖ Le pod sera trait√© selon la logique du profile correspondant dans le scheduler configur√©.

---

### üîπ Sc√©nario 3 : Diagnostiquer un mauvais comportement de planification

**Probl√®me** : Des pods sont mal r√©partis sur les n≈ìuds malgr√© la configuration.

**Solution** :

1. Activer les logs verbeux du scheduler :

   ```bash
   kube-scheduler --v=5 --config=/etc/kubernetes/scheduler-config.yaml
   ```

2. V√©rifier quel plugin est utilis√© pour le scoring :

   ```bash
   grep "Score plugin" /var/log/kube-scheduler.log
   ```

‚úÖ Permet de confirmer que le bon profile a √©t√© appliqu√©.

---

### üîπ Sc√©nario 4 : Ajouter un plugin personnalis√© dans un profile

**Probl√®me** : Vous avez un plugin personnalis√© √† ins√©rer dans le processus de planification.

**Solution** :

1. Compiler le plugin avec Go, l‚Äôenregistrer dans le scheduler.

2. Ajouter dans la configuration :

```yaml
profiles:
  - schedulerName: custom-scheduler
    plugins:
      score:
        enabled:
          - name: MyCustomScorer
    pluginConfig:
      - name: MyCustomScorer
        args:
          weight: 10
```

‚úÖ Le scheduler utilisera votre plugin avec le profile configur√©.

---

### üîπ Sc√©nario 5 : Monitorer les profils de scheduling avec des m√©triques

**Probl√®me** : Vous souhaitez observer le comportement de chaque profile.

**Solution** :

1. Activer l‚Äôendpoint de m√©triques (d√©j√† activ√© par d√©faut sur `:10259`).

2. Interroger les m√©triques :

```bash
curl -k https://localhost:10259/metrics | grep scheduler_profile
```

3. Ajouter un job Prometheus :

```yaml
- job_name: 'scheduler-profiles'
  metrics_path: /metrics
  static_configs:
    - targets: ['localhost:10259']
```

‚úÖ Vous obtenez des m√©triques par profile comme `scheduler_plugin_execution_duration_seconds`.

---

## ‚úÖ Bonnes pratiques

* Toujours documenter les profils et leur usage pr√©vu.
* V√©rifier que les `schedulerName` utilis√©s dans les pods correspondent bien √† ceux des profiles.
* Ne pas dupliquer inutilement des profils ; factoriser les comportements communs.
* Utiliser les logs de haut niveau (`--v=5`) pour observer les d√©cisions prises.
* Superviser les performances de chaque profile avec Prometheus.

---

## üìò Conclusion g√©n√©rale du module Logging & Monitoring (niveau CKA)

Les notions couvertes dans ce cours ‚Äî de *Labels and Selectors* √† *Scheduler Profiles* ‚Äî permettent non seulement une meilleure ma√Ætrise du **comportement du planificateur Kubernetes**, mais aussi une **visibilit√© op√©rationnelle** essentielle √† tout ing√©nieur DevOps ou SRE.

Vous avez d√©sormais :

* des **sc√©narios r√©els**, directement applicables,
* les **commandes Kubernetes** pr√©cises pour diagnostiquer et intervenir,
* une compr√©hension approfondie du r√¥le de **l‚Äôobservabilit√©** dans la fiabilit√© d‚Äôun cluster.

---








